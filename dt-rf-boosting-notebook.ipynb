{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Training a Decision Tree or a Random Forest on a classification problem, and compare the latter with using adaBoost\n",
    "\n",
    "**Author: Pr Fabien MOUTARDE, Center for Robotics, MINES ParisTech, PSL Universit√© Paris**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decision Trees with SciKit-Learn on a very simple dataset\n",
    "\n",
    "**We will first work on very simple classic dataset: Iris, which is a classification problem corresponding to determination of iris flower sub-species based on a few geometric characteristics of the flower.**\n",
    "\n",
    "**Please FIRST READ the [*Iris DATASET DESCRIPTION*](http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html#sphx-glr-auto-examples-datasets-plot-iris-dataset-py).**\n",
    "In this classification problem, there are 3 classes, with a total of 150 examples (each one with 4 input). Please **now execute code cell below to load and view the dataset**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Number_of_examples, example_size) =  (150, 4) \n",
      "\n",
      "Input =  [5.1 3.5 1.4 0.2]  , Label =  0\n",
      "Input =  [4.9 3.  1.4 0.2]  , Label =  0\n",
      "Input =  [4.7 3.2 1.3 0.2]  , Label =  0\n",
      "Input =  [4.6 3.1 1.5 0.2]  , Label =  0\n",
      "Input =  [5.  3.6 1.4 0.2]  , Label =  0\n",
      "Input =  [5.4 3.9 1.7 0.4]  , Label =  0\n",
      "Input =  [4.6 3.4 1.4 0.3]  , Label =  0\n",
      "Input =  [5.  3.4 1.5 0.2]  , Label =  0\n",
      "Input =  [4.4 2.9 1.4 0.2]  , Label =  0\n",
      "Input =  [4.9 3.1 1.5 0.1]  , Label =  0\n",
      "Input =  [5.4 3.7 1.5 0.2]  , Label =  0\n",
      "Input =  [4.8 3.4 1.6 0.2]  , Label =  0\n",
      "Input =  [4.8 3.  1.4 0.1]  , Label =  0\n",
      "Input =  [4.3 3.  1.1 0.1]  , Label =  0\n",
      "Input =  [5.8 4.  1.2 0.2]  , Label =  0\n",
      "Input =  [5.7 4.4 1.5 0.4]  , Label =  0\n",
      "Input =  [5.4 3.9 1.3 0.4]  , Label =  0\n",
      "Input =  [5.1 3.5 1.4 0.3]  , Label =  0\n",
      "Input =  [5.7 3.8 1.7 0.3]  , Label =  0\n",
      "Input =  [5.1 3.8 1.5 0.3]  , Label =  0\n",
      "Input =  [5.4 3.4 1.7 0.2]  , Label =  0\n",
      "Input =  [5.1 3.7 1.5 0.4]  , Label =  0\n",
      "Input =  [4.6 3.6 1.  0.2]  , Label =  0\n",
      "Input =  [5.1 3.3 1.7 0.5]  , Label =  0\n",
      "Input =  [4.8 3.4 1.9 0.2]  , Label =  0\n",
      "Input =  [5.  3.  1.6 0.2]  , Label =  0\n",
      "Input =  [5.  3.4 1.6 0.4]  , Label =  0\n",
      "Input =  [5.2 3.5 1.5 0.2]  , Label =  0\n",
      "Input =  [5.2 3.4 1.4 0.2]  , Label =  0\n",
      "Input =  [4.7 3.2 1.6 0.2]  , Label =  0\n",
      "Input =  [4.8 3.1 1.6 0.2]  , Label =  0\n",
      "Input =  [5.4 3.4 1.5 0.4]  , Label =  0\n",
      "Input =  [5.2 4.1 1.5 0.1]  , Label =  0\n",
      "Input =  [5.5 4.2 1.4 0.2]  , Label =  0\n",
      "Input =  [4.9 3.1 1.5 0.2]  , Label =  0\n",
      "Input =  [5.  3.2 1.2 0.2]  , Label =  0\n",
      "Input =  [5.5 3.5 1.3 0.2]  , Label =  0\n",
      "Input =  [4.9 3.6 1.4 0.1]  , Label =  0\n",
      "Input =  [4.4 3.  1.3 0.2]  , Label =  0\n",
      "Input =  [5.1 3.4 1.5 0.2]  , Label =  0\n",
      "Input =  [5.  3.5 1.3 0.3]  , Label =  0\n",
      "Input =  [4.5 2.3 1.3 0.3]  , Label =  0\n",
      "Input =  [4.4 3.2 1.3 0.2]  , Label =  0\n",
      "Input =  [5.  3.5 1.6 0.6]  , Label =  0\n",
      "Input =  [5.1 3.8 1.9 0.4]  , Label =  0\n",
      "Input =  [4.8 3.  1.4 0.3]  , Label =  0\n",
      "Input =  [5.1 3.8 1.6 0.2]  , Label =  0\n",
      "Input =  [4.6 3.2 1.4 0.2]  , Label =  0\n",
      "Input =  [5.3 3.7 1.5 0.2]  , Label =  0\n",
      "Input =  [5.  3.3 1.4 0.2]  , Label =  0\n",
      "Input =  [7.  3.2 4.7 1.4]  , Label =  1\n",
      "Input =  [6.4 3.2 4.5 1.5]  , Label =  1\n",
      "Input =  [6.9 3.1 4.9 1.5]  , Label =  1\n",
      "Input =  [5.5 2.3 4.  1.3]  , Label =  1\n",
      "Input =  [6.5 2.8 4.6 1.5]  , Label =  1\n",
      "Input =  [5.7 2.8 4.5 1.3]  , Label =  1\n",
      "Input =  [6.3 3.3 4.7 1.6]  , Label =  1\n",
      "Input =  [4.9 2.4 3.3 1. ]  , Label =  1\n",
      "Input =  [6.6 2.9 4.6 1.3]  , Label =  1\n",
      "Input =  [5.2 2.7 3.9 1.4]  , Label =  1\n",
      "Input =  [5.  2.  3.5 1. ]  , Label =  1\n",
      "Input =  [5.9 3.  4.2 1.5]  , Label =  1\n",
      "Input =  [6.  2.2 4.  1. ]  , Label =  1\n",
      "Input =  [6.1 2.9 4.7 1.4]  , Label =  1\n",
      "Input =  [5.6 2.9 3.6 1.3]  , Label =  1\n",
      "Input =  [6.7 3.1 4.4 1.4]  , Label =  1\n",
      "Input =  [5.6 3.  4.5 1.5]  , Label =  1\n",
      "Input =  [5.8 2.7 4.1 1. ]  , Label =  1\n",
      "Input =  [6.2 2.2 4.5 1.5]  , Label =  1\n",
      "Input =  [5.6 2.5 3.9 1.1]  , Label =  1\n",
      "Input =  [5.9 3.2 4.8 1.8]  , Label =  1\n",
      "Input =  [6.1 2.8 4.  1.3]  , Label =  1\n",
      "Input =  [6.3 2.5 4.9 1.5]  , Label =  1\n",
      "Input =  [6.1 2.8 4.7 1.2]  , Label =  1\n",
      "Input =  [6.4 2.9 4.3 1.3]  , Label =  1\n",
      "Input =  [6.6 3.  4.4 1.4]  , Label =  1\n",
      "Input =  [6.8 2.8 4.8 1.4]  , Label =  1\n",
      "Input =  [6.7 3.  5.  1.7]  , Label =  1\n",
      "Input =  [6.  2.9 4.5 1.5]  , Label =  1\n",
      "Input =  [5.7 2.6 3.5 1. ]  , Label =  1\n",
      "Input =  [5.5 2.4 3.8 1.1]  , Label =  1\n",
      "Input =  [5.5 2.4 3.7 1. ]  , Label =  1\n",
      "Input =  [5.8 2.7 3.9 1.2]  , Label =  1\n",
      "Input =  [6.  2.7 5.1 1.6]  , Label =  1\n",
      "Input =  [5.4 3.  4.5 1.5]  , Label =  1\n",
      "Input =  [6.  3.4 4.5 1.6]  , Label =  1\n",
      "Input =  [6.7 3.1 4.7 1.5]  , Label =  1\n",
      "Input =  [6.3 2.3 4.4 1.3]  , Label =  1\n",
      "Input =  [5.6 3.  4.1 1.3]  , Label =  1\n",
      "Input =  [5.5 2.5 4.  1.3]  , Label =  1\n",
      "Input =  [5.5 2.6 4.4 1.2]  , Label =  1\n",
      "Input =  [6.1 3.  4.6 1.4]  , Label =  1\n",
      "Input =  [5.8 2.6 4.  1.2]  , Label =  1\n",
      "Input =  [5.  2.3 3.3 1. ]  , Label =  1\n",
      "Input =  [5.6 2.7 4.2 1.3]  , Label =  1\n",
      "Input =  [5.7 3.  4.2 1.2]  , Label =  1\n",
      "Input =  [5.7 2.9 4.2 1.3]  , Label =  1\n",
      "Input =  [6.2 2.9 4.3 1.3]  , Label =  1\n",
      "Input =  [5.1 2.5 3.  1.1]  , Label =  1\n",
      "Input =  [5.7 2.8 4.1 1.3]  , Label =  1\n",
      "Input =  [6.3 3.3 6.  2.5]  , Label =  2\n",
      "Input =  [5.8 2.7 5.1 1.9]  , Label =  2\n",
      "Input =  [7.1 3.  5.9 2.1]  , Label =  2\n",
      "Input =  [6.3 2.9 5.6 1.8]  , Label =  2\n",
      "Input =  [6.5 3.  5.8 2.2]  , Label =  2\n",
      "Input =  [7.6 3.  6.6 2.1]  , Label =  2\n",
      "Input =  [4.9 2.5 4.5 1.7]  , Label =  2\n",
      "Input =  [7.3 2.9 6.3 1.8]  , Label =  2\n",
      "Input =  [6.7 2.5 5.8 1.8]  , Label =  2\n",
      "Input =  [7.2 3.6 6.1 2.5]  , Label =  2\n",
      "Input =  [6.5 3.2 5.1 2. ]  , Label =  2\n",
      "Input =  [6.4 2.7 5.3 1.9]  , Label =  2\n",
      "Input =  [6.8 3.  5.5 2.1]  , Label =  2\n",
      "Input =  [5.7 2.5 5.  2. ]  , Label =  2\n",
      "Input =  [5.8 2.8 5.1 2.4]  , Label =  2\n",
      "Input =  [6.4 3.2 5.3 2.3]  , Label =  2\n",
      "Input =  [6.5 3.  5.5 1.8]  , Label =  2\n",
      "Input =  [7.7 3.8 6.7 2.2]  , Label =  2\n",
      "Input =  [7.7 2.6 6.9 2.3]  , Label =  2\n",
      "Input =  [6.  2.2 5.  1.5]  , Label =  2\n",
      "Input =  [6.9 3.2 5.7 2.3]  , Label =  2\n",
      "Input =  [5.6 2.8 4.9 2. ]  , Label =  2\n",
      "Input =  [7.7 2.8 6.7 2. ]  , Label =  2\n",
      "Input =  [6.3 2.7 4.9 1.8]  , Label =  2\n",
      "Input =  [6.7 3.3 5.7 2.1]  , Label =  2\n",
      "Input =  [7.2 3.2 6.  1.8]  , Label =  2\n",
      "Input =  [6.2 2.8 4.8 1.8]  , Label =  2\n",
      "Input =  [6.1 3.  4.9 1.8]  , Label =  2\n",
      "Input =  [6.4 2.8 5.6 2.1]  , Label =  2\n",
      "Input =  [7.2 3.  5.8 1.6]  , Label =  2\n",
      "Input =  [7.4 2.8 6.1 1.9]  , Label =  2\n",
      "Input =  [7.9 3.8 6.4 2. ]  , Label =  2\n",
      "Input =  [6.4 2.8 5.6 2.2]  , Label =  2\n",
      "Input =  [6.3 2.8 5.1 1.5]  , Label =  2\n",
      "Input =  [6.1 2.6 5.6 1.4]  , Label =  2\n",
      "Input =  [7.7 3.  6.1 2.3]  , Label =  2\n",
      "Input =  [6.3 3.4 5.6 2.4]  , Label =  2\n",
      "Input =  [6.4 3.1 5.5 1.8]  , Label =  2\n",
      "Input =  [6.  3.  4.8 1.8]  , Label =  2\n",
      "Input =  [6.9 3.1 5.4 2.1]  , Label =  2\n",
      "Input =  [6.7 3.1 5.6 2.4]  , Label =  2\n",
      "Input =  [6.9 3.1 5.1 2.3]  , Label =  2\n",
      "Input =  [5.8 2.7 5.1 1.9]  , Label =  2\n",
      "Input =  [6.8 3.2 5.9 2.3]  , Label =  2\n",
      "Input =  [6.7 3.3 5.7 2.5]  , Label =  2\n",
      "Input =  [6.7 3.  5.2 2.3]  , Label =  2\n",
      "Input =  [6.3 2.5 5.  1.9]  , Label =  2\n",
      "Input =  [6.5 3.  5.2 2. ]  , Label =  2\n",
      "Input =  [6.2 3.4 5.4 2.3]  , Label =  2\n",
      "Input =  [5.9 3.  5.1 1.8]  , Label =  2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load Iris classification dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Print all 150 examples\n",
    "print(\"(Number_of_examples, example_size) = \" , iris.data.shape, \"\\n\")\n",
    "for i in range(0, 150) :\n",
    "    print('Input = ', iris.data[i], ' , Label = ', iris.target[i] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building, training and evaluating a simple Decision Tree classifier**\n",
    "\n",
    "The SciKit-learn class for Decision Tree classifiers is sklearn.tree.DecisionTreeClassifier.\n",
    "\n",
    "**Please FIRST READ (and understand!) the [*DecisionTreeClassifier DOCUMENTATION*](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) to understand all parameters of the contructor.**\n",
    "\n",
    "**You can then begin by running the code block below, in which default set of parameter values has been used.** If graphical view works, look at the structure of the learnt decision tree.\n",
    "\n",
    "**Then, check the influence of MAIN parameters for Decision Tree classifier, i.e.:**\n",
    " - **homegeneity criterion ('gini' or 'entropy')**\n",
    " - **max_depth**\n",
    " - **min_samples_split**\n",
    " \n",
    "NB : Note that post-training *PRUNING* IS unfortunately *NOT* implemented in SciKit-Learn Decision-Trees :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:310: FutureWarning: The min_impurity_split parameter is deprecated. Its default value has changed from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  FutureWarning)\n",
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:327: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(criterion='entropy', max_depth=5,\n",
      "                       min_impurity_split=1e-07, presort=False)\n",
      "Acuracy (on test set) =  0.9333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.82      1.00      0.90        14\n",
      "           2       1.00      0.81      0.90        16\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "\n",
      " CONFUSION MATRIX\n",
      "[[15  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  3 13]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training and test part\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3)\n",
    "\n",
    "# Learn a Decision Tree\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=5, \n",
    "                                  min_samples_split=2, min_samples_leaf=1, \n",
    "                                  min_weight_fraction_leaf=0.0, max_features=None, \n",
    "                                  random_state=None, max_leaf_nodes=None, \n",
    "                                  min_impurity_split=1e-07, class_weight=None, presort=False)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Graphical view of learnt Decision Tree\n",
    "tree.plot_tree(clf) \n",
    "\n",
    "# Evaluate acuracy on test data\n",
    "print(clf)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"Acuracy (on test set) = \", score)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print( classification_report(y_true, y_pred) )\n",
    "print(\"\\n CONFUSION MATRIX\")\n",
    "print( confusion_matrix(y_true, y_pred) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Trees on a  MORE REALISTIC DATASET: HANDWRITTEN DIGITS\n",
    "\n",
    "**Please FIRST READ the [*Digits DATASET DESCRIPTION*](http://scikit-learn.org/stable/auto_examples/datasets/plot_digits_last_image.html#sphx-glr-auto-examples-datasets-plot-digits-last-image-py).**\n",
    "\n",
    "In this classification problem, there are 10 classes, with a total of 1797 examples (each one being a 64D vector corresponding to an 8x8 pixmap). Please **now execute code cell below to load the dataset, visualize a typical example, and train a Desicion Tree on it**. \n",
    "The original code uses a **voluntarily SUBOPTIMAL set of learning hyperparameters values, which reaches ~66% test acuracy. Try to play with them in order to improve acuracy.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number_of-examples =  1797\n",
      "\n",
      " Plot of first example\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=5, min_impurity_split=1e-07,\n",
      "                       min_samples_split=4, presort=False)\n",
      "Acuracy (on test set) =  0.6384872080088988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93        81\n",
      "           1       0.36      0.27      0.31        88\n",
      "           2       0.63      0.13      0.22        90\n",
      "           3       0.44      0.72      0.54        93\n",
      "           4       0.84      0.70      0.77        98\n",
      "           5       0.94      0.87      0.90        91\n",
      "           6       0.86      0.89      0.87        89\n",
      "           7       0.77      0.88      0.82        83\n",
      "           8       0.33      0.71      0.45        87\n",
      "           9       0.94      0.32      0.48        99\n",
      "\n",
      "    accuracy                           0.64       899\n",
      "   macro avg       0.70      0.65      0.63       899\n",
      "weighted avg       0.70      0.64      0.63       899\n",
      "\n",
      "\n",
      " CONFUSION MATRIX\n",
      "[[77  0  0  0  1  0  1  0  2  0]\n",
      " [ 0 24  0 12  2  0  3  2 45  0]\n",
      " [ 1 12 12  4  0  0  6  0 55  0]\n",
      " [ 0 11  2 67  1  1  0  2  8  1]\n",
      " [ 6  4  2  2 69  0  3  5  7  0]\n",
      " [ 0  4  1  4  2 79  0  1  0  0]\n",
      " [ 0  4  1  0  4  1 79  0  0  0]\n",
      " [ 0  1  1  0  2  0  0 73  6  0]\n",
      " [ 0  5  0 15  0  0  0  4 62  1]\n",
      " [ 0  2  0 50  1  3  0  8  3 32]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:310: FutureWarning: The min_impurity_split parameter is deprecated. Its default value has changed from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  FutureWarning)\n",
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:327: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "n_samples = len(digits.images)\n",
    "print(\"Number_of-examples = \", n_samples)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"\\n Plot of first example\")\n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0]) \n",
    "plt.show() \n",
    "\n",
    "# Flatten the images, to turn data in a (samples, feature) matrix:\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Split dataset into training and test part\n",
    "X = data\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "# Create and train a Decision Tree Classifier\n",
    "clf = tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=5, \n",
    "                                  min_samples_split=4, min_samples_leaf=1, \n",
    "                                  min_weight_fraction_leaf=0.0, max_features=None, \n",
    "                                  random_state=None, max_leaf_nodes=None, \n",
    "                                  min_impurity_split=1e-07, class_weight=None, presort=False)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate acuracy on test data\n",
    "print(clf)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"Acuracy (on test set) = \", score)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print( classification_report(y_true, y_pred) )\n",
    "print(\"\\n CONFUSION MATRIX\")\n",
    "print( confusion_matrix(y_true, y_pred) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question: According to the confusion matrices, what digits are the most confused with each other?__\n",
    "\n",
    "__Answer:__ 1 and 7, 2 and 7, 3 and 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, find somewhat optimized values for the set of 3 main hyper-parameters for DecisionTree learning, by using GRID-SEARCH WITH CROSS-VALIDATION** (see cross-validation example from the Multi-Layer Perceptron notebook used in earlier practical session). __Put the code in the cell below:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid=[{'criterion': ('entropy', 'gini'),\n",
       "                          'max_depth': [5, 10, 20, 50],\n",
       "                          'min_samples_split': [2, 4, 6, 8]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "param_grid = [\n",
    "  {'criterion':('entropy', 'gini'), \n",
    "   'max_depth':[5, 10, 20, 50],\n",
    "   'min_samples_split': [2, 4, 6, 8]}\n",
    " ]\n",
    "\n",
    "# Cross-validation grid-search (for finding best possible accuracy)\n",
    "clf = GridSearchCV(tree.DecisionTreeClassifier(splitter='best', \n",
    "                                  min_samples_leaf=1, \n",
    "                                  min_weight_fraction_leaf=0.0, max_features=None, \n",
    "                                  random_state=None, max_leaf_nodes=None, \n",
    "                                  ) , \n",
    "                   param_grid, cv=3, scoring='accuracy') \n",
    "# NOTE THAT YOU CAN USE OTHER VALUE FOR cv (# of folds) and OTHER SCORING CRITERIA OTHER THAN 'accuracy'\n",
    "    \n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy (on test set) =  0.9866518353726362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       178\n",
      "           1       0.97      1.00      0.98       182\n",
      "           2       0.98      0.99      0.99       177\n",
      "           3       0.98      0.99      0.99       183\n",
      "           4       0.99      0.99      0.99       181\n",
      "           5       0.99      0.99      0.99       182\n",
      "           6       0.99      0.97      0.98       181\n",
      "           7       0.99      0.99      0.99       179\n",
      "           8       1.00      0.98      0.99       174\n",
      "           9       1.00      0.97      0.99       180\n",
      "\n",
      "    accuracy                           0.99      1797\n",
      "   macro avg       0.99      0.99      0.99      1797\n",
      "weighted avg       0.99      0.99      0.99      1797\n",
      "\n",
      "\n",
      " CONFUSION MATRIX\n",
      "[[177   0   1   0   0   0   0   0   0   0]\n",
      " [  0 182   0   0   0   0   0   0   0   0]\n",
      " [  0   1 176   0   0   0   0   0   0   0]\n",
      " [  0   0   2 181   0   0   0   0   0   0]\n",
      " [  2   0   0   0 179   0   0   0   0   0]\n",
      " [  0   0   1   1   0 180   0   0   0   0]\n",
      " [  2   2   0   0   0   1 176   0   0   0]\n",
      " [  0   0   0   0   0   1   0 178   0   0]\n",
      " [  0   1   0   1   0   0   1   1 170   0]\n",
      " [  0   2   0   1   2   0   0   0   0 175]]\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=50, min_samples_split=4)\n"
     ]
    }
   ],
   "source": [
    "score = clf.score(X_test, y_test)\n",
    "print(\"Acuracy (on test set) = \", score)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true, y_pred = y, clf.predict(X)\n",
    "print( classification_report(y_true, y_pred) )\n",
    "print(\"\\n CONFUSION MATRIX\")\n",
    "print( confusion_matrix(y_true, y_pred) )\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question: What best value have you managed to reach for TEST accuracy of your DecisionTree after you properly gridSearched its hyper-parameters using CrossValidation?__\n",
    "\n",
    "__Answer:__ The best value that I have got is $accuracy = 0.99$, with $citerion = 'entropy'$, $max\\_depth = 50$ and $min\\_sample\\_split = 4$.\n",
    "\n",
    "\n",
    "In order to improve result, the most natural step is to combine SEVERAL decision trees, using the Ensemble model called Random Forest: see below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building, training and evaluating a Random Forest classifier\n",
    "\n",
    "The SciKit-learn class for Random Forest classifiers is sklearn.ensemble.RandomForestClassifier.\n",
    "\n",
    "**Please FIRST READ (and understand!) the [*RandomForestClassifier DOCUMENTATION*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to understand all parameters of the contructor.**\n",
    "\n",
    "**Then you can begin by running the code block below, in which default set of parameter values has been used.** As you will see, a RandomForest (even rather small) can easily outperform single Decision Tree. \n",
    "\n",
    "**Then, check the influence of MAIN parameters for Random Forest classifier, i.e.:**\n",
    " - **n_estimators (number of trees in forest)**\n",
    " - **max_depth**\n",
    " - **max_features (max number of features used in each tree)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators= 10  max_depth= None max_features= auto\n",
      "RandomForestClassifier(min_impurity_split=1e-07, n_estimators=10, n_jobs=1)\n",
      "Acuracy (on test set) =  0.9199110122358176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96        81\n",
      "           1       0.85      0.95      0.90        88\n",
      "           2       0.92      0.93      0.93        90\n",
      "           3       0.93      0.94      0.93        93\n",
      "           4       0.95      0.90      0.92        98\n",
      "           5       0.94      0.93      0.94        91\n",
      "           6       0.96      0.97      0.96        89\n",
      "           7       0.89      0.99      0.94        83\n",
      "           8       0.90      0.82      0.86        87\n",
      "           9       0.92      0.83      0.87        99\n",
      "\n",
      "    accuracy                           0.92       899\n",
      "   macro avg       0.92      0.92      0.92       899\n",
      "weighted avg       0.92      0.92      0.92       899\n",
      "\n",
      "\n",
      " CONFUSION MATRIX\n",
      "[[78  0  0  0  2  0  0  0  0  1]\n",
      " [ 0 84  1  1  1  0  0  0  1  0]\n",
      " [ 1  0 84  1  1  0  1  1  1  0]\n",
      " [ 0  1  2 87  0  2  0  1  0  0]\n",
      " [ 1  4  0  0 88  0  3  2  0  0]\n",
      " [ 2  0  0  0  0 85  0  0  2  2]\n",
      " [ 0  0  0  0  1  1 86  0  0  1]\n",
      " [ 0  1  0  0  0  0  0 82  0  0]\n",
      " [ 0  7  4  2  0  0  0  0 71  3]\n",
      " [ 0  2  0  3  0  2  0  6  4 82]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:310: FutureWarning: The min_impurity_split parameter is deprecated. Its default value has changed from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  FutureWarning)\n",
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:310: FutureWarning: The min_impurity_split parameter is deprecated. Its default value has changed from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  FutureWarning)\n",
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:310: FutureWarning: The min_impurity_split parameter is deprecated. Its default value has changed from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  FutureWarning)\n",
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:310: FutureWarning: The min_impurity_split parameter is deprecated. Its default value has changed from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  FutureWarning)\n",
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:310: FutureWarning: The min_impurity_split parameter is deprecated. Its default value has changed from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  FutureWarning)\n",
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:310: FutureWarning: The min_impurity_split parameter is deprecated. Its default value has changed from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  FutureWarning)\n",
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:310: FutureWarning: The min_impurity_split parameter is deprecated. Its default value has changed from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  FutureWarning)\n",
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:310: FutureWarning: The min_impurity_split parameter is deprecated. Its default value has changed from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  FutureWarning)\n",
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:310: FutureWarning: The min_impurity_split parameter is deprecated. Its default value has changed from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  FutureWarning)\n",
      "C:\\Users\\wangfu\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:310: FutureWarning: The min_impurity_split parameter is deprecated. Its default value has changed from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None,\n",
    "                             min_samples_split=2, min_samples_leaf=1, \n",
    "                             min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                             max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, \n",
    "                             oob_score=False, n_jobs=1, random_state=None, \n",
    "                             verbose=0, warm_start=False, class_weight=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"n_estimators=\", clf.n_estimators, \" max_depth=\",clf.max_depth,\n",
    "      \"max_features=\", clf.max_features)\n",
    "\n",
    "# Evaluate acuracy on test data\n",
    "print(clf)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"Acuracy (on test set) = \", score)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print( classification_report(y_true, y_pred) )\n",
    "print(\"\\n CONFUSION MATRIX\")\n",
    "print( confusion_matrix(y_true, y_pred) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, find somewhat optimized values the set of 3 main hyper-parameters for RandomForest, by using CROSS-VALIDATION** (see cross-validation example from the Multi-Layer Perceptron notebook used in earlier practical session). __Put the code in the cell below:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=RandomForestClassifier(min_samples_split=4, n_jobs=1),\n",
       "             param_grid=[{'max_depth': [5, 10, 20, 50],\n",
       "                          'max_features': ('auto', 'sqrt', 'log2'),\n",
       "                          'n_estimators': [5, 10, 20, 50]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "  {'n_estimators':[5, 10, 20, 50], \n",
    "   'max_depth':[5, 10, 20, 50],\n",
    "   'max_features': ('auto', 'sqrt', 'log2')}\n",
    " ]\n",
    "\n",
    "# Cross-validation grid-search (for finding best possible accuracy)\n",
    "clf = GridSearchCV(RandomForestClassifier(criterion='gini',\n",
    "                             min_samples_split=4, min_samples_leaf=1, \n",
    "                             min_weight_fraction_leaf=0.0, \n",
    "                             max_leaf_nodes=None, bootstrap=True, \n",
    "                             oob_score=False, n_jobs=1, random_state=None, \n",
    "                             verbose=0), \n",
    "                   param_grid, cv=3, scoring='accuracy') \n",
    "# NOTE THAT YOU CAN USE OTHER VALUE FOR cv (# of folds) and OTHER SCORING CRITERIA OTHER THAN 'accuracy'\n",
    "    \n",
    "clf.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy (on test set) =  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       178\n",
      "           1       1.00      1.00      1.00       182\n",
      "           2       1.00      1.00      1.00       177\n",
      "           3       1.00      1.00      1.00       183\n",
      "           4       1.00      1.00      1.00       181\n",
      "           5       1.00      1.00      1.00       182\n",
      "           6       1.00      1.00      1.00       181\n",
      "           7       1.00      1.00      1.00       179\n",
      "           8       1.00      1.00      1.00       174\n",
      "           9       1.00      1.00      1.00       180\n",
      "\n",
      "    accuracy                           1.00      1797\n",
      "   macro avg       1.00      1.00      1.00      1797\n",
      "weighted avg       1.00      1.00      1.00      1797\n",
      "\n",
      "\n",
      " CONFUSION MATRIX\n",
      "[[178   0   0   0   0   0   0   0   0   0]\n",
      " [  0 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0 177   0   0   0   0   0   0   0]\n",
      " [  0   0   0 183   0   0   0   0   0   0]\n",
      " [  0   0   0   0 181   0   0   0   0   0]\n",
      " [  0   0   0   0   0 182   0   0   0   0]\n",
      " [  0   0   0   0   0   0 181   0   0   0]\n",
      " [  0   0   0   0   0   0   0 179   0   0]\n",
      " [  0   0   0   0   0   0   0   0 174   0]\n",
      " [  0   0   0   0   0   0   0   0   0 180]]\n",
      "RandomForestClassifier(max_depth=50, min_samples_split=4, n_estimators=50,\n",
      "                       n_jobs=1)\n"
     ]
    }
   ],
   "source": [
    "score = clf.score(X_test, y_test)\n",
    "print(\"Acuracy (on test set) = \", score)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true, y_pred = y, clf.predict(X)\n",
    "print( classification_report(y_true, y_pred) )\n",
    "print(\"\\n CONFUSION MATRIX\")\n",
    "print( confusion_matrix(y_true, y_pred) )\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question: What best value have you managed to reach for TEST accuracy of your RandomForest after you properly gridSearched its hyper-parameters using CrossValidation?__\n",
    "\n",
    "__Answer:__ The best value I realised is $accuracy = 1$, with $max\\_depth = 50$, $n\\_estimator = 50$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Building, training and evaluating an AdaBoost classifier\n",
    "\n",
    "The SciKit-learn class for adaBoost is sklearn.ensemble.AdaBoostClassifier.\n",
    "\n",
    "**Please FIRST READ (and understand!) the [*AdaBoostClassifier DOCUMENTATION*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier) to understand all parameters of the contructor.**\n",
    "\n",
    "**Then begin by running the code block below, in which a default set of parameter values has been used.** \n",
    "\n",
    "**Then, check the influence of MAIN parameters for adaBoost classifier, i.e.:**\n",
    " - **base_estimator (ie type of Weak Classifier/Learner)** \n",
    " - **n_estimators (number of boosting iterations, and therefore also number of weak classifiers)**\n",
    " - algorithm\n",
    " \n",
    "**Finally, check which other types of classifiers can be used as Weak Classifier with the adaBoost implementation of SciKit-Learn.**\n",
    "NB: in principle it is possible to use MLP classifiers as weak classifiers, but not with SciKit-learn implementation of MLPClassifier (because weighting of examples is not handled by its implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weak_learner: DecisionTreeClassifier(max_depth=6)\n",
      "Weights of weak classifiers:  [3.8694389  4.01673598 5.13221083 5.16632464 4.74817543 4.54296183\n",
      " 4.61373859 5.3382181  4.53520878 4.70156517 4.88058392 6.16761423\n",
      " 5.02814498 4.33003157 5.02998452]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators= 15\n",
      "Acuracy (on test set) =  0.917686318131257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97        81\n",
      "           1       0.92      0.94      0.93        88\n",
      "           2       0.98      0.91      0.94        90\n",
      "           3       0.91      0.87      0.89        93\n",
      "           4       0.90      0.94      0.92        98\n",
      "           5       0.93      0.97      0.95        91\n",
      "           6       0.94      0.96      0.95        89\n",
      "           7       0.94      0.90      0.92        83\n",
      "           8       0.78      0.92      0.85        87\n",
      "           9       0.93      0.82      0.87        99\n",
      "\n",
      "    accuracy                           0.92       899\n",
      "   macro avg       0.92      0.92      0.92       899\n",
      "weighted avg       0.92      0.92      0.92       899\n",
      "\n",
      "\n",
      " CONFUSION MATRIX\n",
      "[[78  0  0  0  2  0  1  0  0  0]\n",
      " [ 0 83  0  0  0  1  0  0  4  0]\n",
      " [ 1  1 82  4  0  0  1  0  1  0]\n",
      " [ 0  2  0 81  0  2  1  0  5  2]\n",
      " [ 0  1  0  0 92  1  2  1  1  0]\n",
      " [ 0  0  0  0  1 88  0  0  1  1]\n",
      " [ 0  1  0  0  2  0 85  0  1  0]\n",
      " [ 0  0  0  1  2  1  0 75  3  1]\n",
      " [ 0  2  1  1  0  0  0  1 80  2]\n",
      " [ 1  0  1  2  3  2  0  3  6 81]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Create and train an adaBoost classifier using SMALL Decision Trees as weak classifiers\n",
    "weak_learner = tree.DecisionTreeClassifier(max_depth=6)\n",
    "clf = AdaBoostClassifier(weak_learner, n_estimators=15, learning_rate=1.0, algorithm='SAMME', \n",
    "                         random_state=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"Weak_learner:\", clf.base_estimator)\n",
    "print(\"Weights of weak classifiers: \", clf.estimator_weights_)\n",
    "      \n",
    "# Plot training curves (error = f(iterations))\n",
    "n_iter = clf.n_estimators\n",
    "from sklearn.metrics import zero_one_loss\n",
    "ada_train_err = np.zeros((clf.n_estimators,))\n",
    "for i, y_pred in enumerate(clf.staged_predict(X_train)):\n",
    "    ada_train_err[i] = zero_one_loss(y_pred, y_train)\n",
    "ada_test_err = np.zeros((clf.n_estimators,))\n",
    "for i, y_pred in enumerate(clf.staged_predict(X_test)):\n",
    "    ada_test_err[i] = zero_one_loss(y_pred, y_test)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(np.arange(n_iter) + 1, ada_train_err,\n",
    "        label='Training Error',\n",
    "        color='green')\n",
    "ax.plot(np.arange(n_iter) + 1, ada_test_err,\n",
    "        label='Test Error',\n",
    "        color='orange')\n",
    "ax.set_ylim((0.0, 0.5))\n",
    "ax.set_xlabel('boosting iterations')\n",
    "ax.set_ylabel('error rate')\n",
    "leg = ax.legend(loc='upper right', fancybox=True)\n",
    "plt.show()\n",
    "\n",
    "# Evaluate acuracy on test data\n",
    "print(\"n_estimators=\", clf.n_estimators)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"Acuracy (on test set) = \", score)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print( classification_report(y_true, y_pred) )\n",
    "print(\"\\n CONFUSION MATRIX\")\n",
    "print( confusion_matrix(y_true, y_pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question:__ Looking at the training curves, you can see that **training error goes down to zero rather quickly, but that test_error still continues, after training error is zero, to diminish with increasing iterations**. __Is it normal, and why?__ (check the course!)\n",
    "\n",
    "__Answer:__ It is normal because this is one of the drawbacks of Adaboost. This algorithme is easy to get over-fitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, for the case of _DecisionTree_ weak classifiers, find somewhat optimized values of (max_depth, n_estimators) by using CROSS-VALIDATION.** __Put the code below:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME',\n",
       "                                          base_estimator=DecisionTreeClassifier(max_depth=10)),\n",
       "             param_grid=[{'n_estimators': [5, 10, 20, 50]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "  {'n_estimators':[5, 10, 20, 50], \n",
    "   #'max_depth':[5, 10, 20, 50]\n",
    "   }\n",
    " ]\n",
    "\n",
    "clf = GridSearchCV(AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth = 10), learning_rate=1.0, algorithm='SAMME', \n",
    "                         random_state=None), \n",
    "                   param_grid, cv=3, scoring='accuracy') \n",
    "    \n",
    "clf.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy (on test set) =  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       178\n",
      "           1       1.00      1.00      1.00       182\n",
      "           2       1.00      1.00      1.00       177\n",
      "           3       1.00      1.00      1.00       183\n",
      "           4       1.00      1.00      1.00       181\n",
      "           5       1.00      1.00      1.00       182\n",
      "           6       1.00      1.00      1.00       181\n",
      "           7       1.00      1.00      1.00       179\n",
      "           8       1.00      1.00      1.00       174\n",
      "           9       1.00      1.00      1.00       180\n",
      "\n",
      "    accuracy                           1.00      1797\n",
      "   macro avg       1.00      1.00      1.00      1797\n",
      "weighted avg       1.00      1.00      1.00      1797\n",
      "\n",
      "\n",
      " CONFUSION MATRIX\n",
      "[[178   0   0   0   0   0   0   0   0   0]\n",
      " [  0 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0 177   0   0   0   0   0   0   0]\n",
      " [  0   0   0 183   0   0   0   0   0   0]\n",
      " [  0   0   0   0 181   0   0   0   0   0]\n",
      " [  0   0   0   0   0 182   0   0   0   0]\n",
      " [  0   0   0   0   0   0 181   0   0   0]\n",
      " [  0   0   0   0   0   0   0 179   0   0]\n",
      " [  0   0   0   0   0   0   0   0 174   0]\n",
      " [  0   0   0   0   0   0   0   0   0 180]]\n",
      "AdaBoostClassifier(algorithm='SAMME',\n",
      "                   base_estimator=DecisionTreeClassifier(max_depth=10),\n",
      "                   n_estimators=20)\n"
     ]
    }
   ],
   "source": [
    "score = clf.score(X_test, y_test)\n",
    "print(\"Acuracy (on test set) = \", score)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true, y_pred = y, clf.predict(X)\n",
    "print( classification_report(y_true, y_pred) )\n",
    "print(\"\\n CONFUSION MATRIX\")\n",
    "print( confusion_matrix(y_true, y_pred) )\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question: What best value have you managed to reach for TEST accuracy of your AdaboostClassifier after you properly gridSearched its hyper-parameters using CrossValidation?__\n",
    "\n",
    "__Answer:__ I managed to get $accuracy = 1.0$, with $n\\_estimator = 20$ and $max\\_depth = 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
